"""
Vulnerability Scanner Orchestrator.

This module provides the main vulnerability scanner that orchestrates multiple
API clients, aggregates results, applies policy filtering, and provides
comprehensive vulnerability scanning capabilities.
"""

import asyncio
import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Any, List, Optional, Set
from concurrent.futures import ThreadPoolExecutor

from .models import (
    PackageInfo, ScanRequest, ScanResult, ScanStatus,
    VulnerabilityDetails, VulnerabilitySeverity, VulnerabilitySource,
    BatchScanResult
)
from .api_clients import (
    OSVClient, NVDClient, GitHubAdvisoryClient,
    APIClientConfig, RateLimitConfig, CacheConfig
)
from ..policy_engine.config_manager import ConfigurationManager
from ..policy_engine.models import SecurityPolicyConfig


logger = logging.getLogger(__name__)


@dataclass
class ScannerConfig:
    """Configuration for vulnerability scanner orchestrator."""
    # Client configurations
    osv_enabled: bool = True
    nvd_enabled: bool = True
    github_enabled: bool = True
    
    # API keys
    nvd_api_key: Optional[str] = None
    github_token: Optional[str] = None
    
    # Performance settings
    max_concurrent_scans: int = 10
    timeout_seconds: int = 300
    
    # Result aggregation
    merge_duplicate_vulnerabilities: bool = True
    minimum_confidence_score: float = 0.7
    
    # Policy integration
    apply_security_policy: bool = True
    policy_config_path: Optional[str] = None


class VulnerabilityScanner:
    """Enterprise-grade vulnerability scanner orchestrator."""
    
    def __init__(self, config: Optional[ScannerConfig] = None):
        self.config = config or ScannerConfig()
        self._clients: Dict[VulnerabilitySource, Any] = {}
        self._semaphore = asyncio.Semaphore(self.config.max_concurrent_scans)
        self._policy_config: Optional[SecurityPolicyConfig] = None
        self._config_manager: Optional[ConfigurationManager] = None
        
        # Initialize policy configuration if enabled
        if self.config.apply_security_policy:
            self._config_manager = ConfigurationManager()
            try:
                self._policy_config = self._config_manager.load_configuration("development")
            except Exception as e:
                logger.warning(f"Failed to load security policy: {e}")
    
    async def __aenter__(self):
        """Async context manager entry."""
        await self._initialize_clients()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        await self._cleanup_clients()
    
    async def _initialize_clients(self):
        """Initialize API clients based on configuration."""
        self._clients = {}
        
        # Initialize OSV client
        if self.config.osv_enabled:
            osv_config = APIClientConfig(
                base_url="https://api.osv.dev",
                rate_limit=RateLimitConfig(
                    requests_per_minute=120,
                    requests_per_hour=2000
                ),
                cache=CacheConfig(
                    enabled=True,
                    ttl_seconds=3600,
                    vulnerability_ttl_seconds=7200
                )
            )
            client = OSVClient(osv_config)
            await client.__aenter__()
            self._clients[VulnerabilitySource.OSV] = client
        
        # Initialize NVD client
        if self.config.nvd_enabled:
            rate_config = RateLimitConfig(
                requests_per_minute=50 if self.config.nvd_api_key else 5,
                requests_per_hour=1000 if self.config.nvd_api_key else 100
            )
            nvd_config = APIClientConfig(
                base_url="https://services.nvd.nist.gov/rest/json",
                api_key=self.config.nvd_api_key,
                rate_limit=rate_config,
                cache=CacheConfig(
                    enabled=True,
                    ttl_seconds=7200,  # NVD data changes less frequently
                    vulnerability_ttl_seconds=14400
                )
            )
            client = NVDClient(self.config.nvd_api_key, nvd_config)
            await client.__aenter__()
            self._clients[VulnerabilitySource.NVD] = client
        
        # Initialize GitHub Advisory client
        if self.config.github_enabled:
            rate_config = RateLimitConfig(
                requests_per_minute=5000 if self.config.github_token else 60,
                requests_per_hour=5000 if self.config.github_token else 1000
            )
            github_config = APIClientConfig(
                base_url="https://api.github.com",
                api_key=self.config.github_token,
                rate_limit=rate_config
            )
            client = GitHubAdvisoryClient(self.config.github_token, github_config)
            await client.__aenter__()
            self._clients[VulnerabilitySource.GITHUB_ADVISORY] = client
    
    async def _cleanup_clients(self):
        """Clean up API clients."""
        for client in self._clients.values():
            if hasattr(client, '__aexit__'):
                await client.__aexit__(None, None, None)
        self._clients.clear()
    
    async def scan_package(self, package: PackageInfo, scan_id: Optional[str] = None) -> ScanResult:
        """Scan a single package for vulnerabilities."""
        if not scan_id:
            import uuid
            scan_id = f"scan_{uuid.uuid4().hex[:8]}"
        
        start_time = datetime.now()
        all_vulnerabilities = []
        sources_queried = []
        errors = []
        warnings = []
        
        logger.info(f"Scanning package {package.name}@{package.version} with scan ID {scan_id}")
        
        async with self._semaphore:
            # Query all enabled sources concurrently
            tasks = []
            for source, client in self._clients.items():
                task = self._query_source_with_timeout(client, package, source)
                tasks.append(task)
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Process results
            for source, result in zip(self._clients.keys(), results):
                sources_queried.append(source)
                
                if isinstance(result, Exception):
                    error_msg = f"Error querying {source.value}: {result}"
                    errors.append(error_msg)
                    logger.error(error_msg)
                else:
                    vulnerabilities, source_warnings = result
                    all_vulnerabilities.extend(vulnerabilities)
                    warnings.extend(source_warnings)
                    logger.debug(f"Found {len(vulnerabilities)} vulnerabilities from {source.value}")
        
        # Merge duplicate vulnerabilities
        if self.config.merge_duplicate_vulnerabilities:
            all_vulnerabilities = self._merge_duplicates(all_vulnerabilities)
        
        # Apply security policy filtering
        if self._policy_config:
            all_vulnerabilities = self._apply_policy_filters(all_vulnerabilities)
        
        # Calculate scan duration
        end_time = datetime.now()
        scan_duration = (end_time - start_time).total_seconds()
        
        # Determine scan status
        status = ScanStatus.COMPLETED
        if errors and not all_vulnerabilities:
            status = ScanStatus.FAILED
        elif errors:
            warnings.append(f"Scan completed with {len(errors)} source errors")
        
        result = ScanResult(
            scan_id=scan_id,
            package=package,
            status=status,
            vulnerabilities=all_vulnerabilities,
            scan_timestamp=start_time,
            scan_duration_seconds=scan_duration,
            sources_queried=sources_queried,
            errors=errors,
            warnings=warnings
        )
        
        logger.info(f"Completed scan {scan_id}: {len(all_vulnerabilities)} vulnerabilities found")
        return result
    
    async def scan_batch(self, request: ScanRequest) -> BatchScanResult:
        """Scan multiple packages in batch."""
        logger.info(f"Starting batch scan {request.scan_id} with {len(request.packages)} packages")
        
        start_time = datetime.now()
        results = []
        
        # Create individual scan tasks
        tasks = []
        for package in request.packages:
            task = self.scan_package(
                package,
                scan_id=f"{request.scan_id}_pkg_{package.name}"
            )
            tasks.append(task)
        
        # Execute scans with concurrency control
        completed_results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process batch results
        for package, result in zip(request.packages, completed_results):
            if isinstance(result, Exception):
                # Create failed result for exception
                error_result = ScanResult(
                    scan_id=f"{request.scan_id}_pkg_{package.name}",
                    package=package,
                    status=ScanStatus.FAILED,
                    errors=[f"Scan failed: {result}"]
                )
                results.append(error_result)
            else:
                results.append(result)
        
        end_time = datetime.now()
        
        # Determine batch status
        failed_scans = [r for r in results if r.status == ScanStatus.FAILED]
        if len(failed_scans) == len(results):
            batch_status = ScanStatus.FAILED
        elif failed_scans:
            batch_status = ScanStatus.COMPLETED  # Partial success
        else:
            batch_status = ScanStatus.COMPLETED
        
        batch_result = BatchScanResult(
            batch_id=request.scan_id,
            request=request,
            results=results,
            status=batch_status,
            start_time=start_time,
            end_time=end_time
        )
        
        logger.info(f"Completed batch scan {request.scan_id}: "
                   f"{batch_result.total_vulnerabilities} total vulnerabilities, "
                   f"{len(failed_scans)} failed scans")
        
        return batch_result
    
    async def _query_source_with_timeout(
        self, 
        client, 
        package: PackageInfo, 
        source: VulnerabilitySource
    ) -> tuple[List[VulnerabilityDetails], List[str]]:
        """Query a vulnerability source with timeout handling."""
        warnings = []
        
        try:
            # Apply timeout
            vulnerabilities = await asyncio.wait_for(
                client.query_vulnerabilities(package),
                timeout=self.config.timeout_seconds
            )
            
            # Filter by confidence if applicable
            if self.config.minimum_confidence_score > 0:
                original_count = len(vulnerabilities)
                vulnerabilities = [
                    v for v in vulnerabilities 
                    if self._calculate_confidence_score(v) >= self.config.minimum_confidence_score
                ]
                if len(vulnerabilities) < original_count:
                    warnings.append(f"Filtered {original_count - len(vulnerabilities)} "
                                  f"low-confidence vulnerabilities from {source.value}")
            
            return vulnerabilities, warnings
            
        except asyncio.TimeoutError:
            raise Exception(f"Timeout querying {source.value}")
        except Exception as e:
            raise Exception(f"Error querying {source.value}: {e}")
    
    def _merge_duplicates(self, vulnerabilities: List[VulnerabilityDetails]) -> List[VulnerabilityDetails]:
        """Merge duplicate vulnerabilities from different sources."""
        seen_ids = set()
        merged_vulnerabilities = []
        
        for vuln in vulnerabilities:
            # Primary ID matching
            if vuln.id in seen_ids:
                # Find the existing vulnerability and merge
                for i, existing in enumerate(merged_vulnerabilities):
                    if existing.id == vuln.id:
                        merged_vulnerabilities[i] = self._merge_vulnerability_data(existing, vuln)
                        break
                continue
            
            # Check aliases for duplicates
            merged = False
            for alias in vuln.aliases:
                if alias in seen_ids:
                    # Find the existing vulnerability and merge
                    for i, existing in enumerate(merged_vulnerabilities):
                        if existing.id == alias or alias in existing.aliases:
                            merged_vulnerabilities[i] = self._merge_vulnerability_data(existing, vuln)
                            merged = True
                            break
                    break
            
            # Also check if any of our IDs match existing aliases
            if not merged:
                for i, existing in enumerate(merged_vulnerabilities):
                    if vuln.id in existing.aliases or any(alias in existing.aliases for alias in vuln.aliases):
                        merged_vulnerabilities[i] = self._merge_vulnerability_data(existing, vuln)
                        merged = True
                        break
            
            if not merged:
                merged_vulnerabilities.append(vuln)
                seen_ids.add(vuln.id)
                seen_ids.update(vuln.aliases)
        
        return merged_vulnerabilities
    
    def _merge_vulnerability_data(
        self, 
        existing: VulnerabilityDetails, 
        new: VulnerabilityDetails
    ) -> VulnerabilityDetails:
        """Merge data from two vulnerability records."""
        # Prefer higher quality sources for primary data
        source_priority = {
            VulnerabilitySource.NVD: 3,
            VulnerabilitySource.OSV: 2,
            VulnerabilitySource.GITHUB_ADVISORY: 1
        }
        
        if source_priority.get(new.source, 0) > source_priority.get(existing.source, 0):
            # Use new vulnerability as primary, merge additional data from existing
            merged = VulnerabilityDetails(
                id=new.id,
                summary=new.summary,
                details=new.details,
                severity=new.severity,
                source=new.source,
                cvss_scores=new.cvss_scores + existing.cvss_scores,
                affected=new.affected + existing.affected,
                references=new.references + existing.references,
                aliases=new.aliases + existing.aliases,
                published=new.published or existing.published,
                modified=new.modified or existing.modified,
                withdrawn=new.withdrawn or existing.withdrawn,
                database_specific={**existing.database_specific, **new.database_specific},
                ecosystem_specific={**existing.ecosystem_specific, **new.ecosystem_specific}
            )
        else:
            # Use existing as primary, merge additional data from new
            merged = VulnerabilityDetails(
                id=existing.id,
                summary=existing.summary,
                details=existing.details,
                severity=existing.severity,
                source=existing.source,
                cvss_scores=existing.cvss_scores + new.cvss_scores,
                affected=existing.affected + new.affected,
                references=existing.references + new.references,
                aliases=existing.aliases + new.aliases,
                published=existing.published or new.published,
                modified=existing.modified or new.modified,
                withdrawn=existing.withdrawn or new.withdrawn,
                database_specific={**new.database_specific, **existing.database_specific},
                ecosystem_specific={**new.ecosystem_specific, **existing.ecosystem_specific}
            )
        
        # Deduplicate merged data
        merged.aliases = list(set(merged.aliases))
        merged.references = self._deduplicate_references(merged.references)
        merged.cvss_scores = self._deduplicate_cvss_scores(merged.cvss_scores)
        
        return merged
    
    def _deduplicate_references(self, references):
        """Remove duplicate references."""
        seen_urls = set()
        unique_refs = []
        for ref in references:
            if ref.url not in seen_urls:
                unique_refs.append(ref)
                seen_urls.add(ref.url)
        return unique_refs
    
    def _deduplicate_cvss_scores(self, scores):
        """Remove duplicate CVSS scores."""
        seen_vectors = set()
        unique_scores = []
        for score in scores:
            if score.vector_string not in seen_vectors:
                unique_scores.append(score)
                seen_vectors.add(score.vector_string)
        return unique_scores
    
    def _calculate_confidence_score(self, vulnerability: VulnerabilityDetails) -> float:
        """Calculate confidence score for a vulnerability."""
        score = 0.5  # Base score
        
        # Source reliability
        source_scores = {
            VulnerabilitySource.NVD: 0.4,
            VulnerabilitySource.OSV: 0.3,
            VulnerabilitySource.GITHUB_ADVISORY: 0.2
        }
        score += source_scores.get(vulnerability.source, 0.1)
        
        # Has CVSS score
        if vulnerability.cvss_scores:
            score += 0.2
        
        # Has detailed description
        if len(vulnerability.details) > 100:
            score += 0.1
        
        # Has multiple references
        if len(vulnerability.references) >= 2:
            score += 0.1
        
        # Has aliases (cross-referenced)
        if vulnerability.aliases:
            score += 0.1
        
        return min(score, 1.0)
    
    def _apply_policy_filters(self, vulnerabilities: List[VulnerabilityDetails]) -> List[VulnerabilityDetails]:
        """Apply security policy filtering to vulnerabilities."""
        if not self._policy_config:
            return vulnerabilities
        
        filtered = []
        
        for vuln in vulnerabilities:
            # Check minimum severity threshold
            if self._policy_config.vulnerability_scanning.minimum_severity:
                severity_order = {
                    VulnerabilitySeverity.INFO: 0,
                    VulnerabilitySeverity.LOW: 1,
                    VulnerabilitySeverity.MEDIUM: 2,
                    VulnerabilitySeverity.HIGH: 3,
                    VulnerabilitySeverity.CRITICAL: 4
                }
                
                min_level = severity_order.get(
                    VulnerabilitySeverity(self._policy_config.vulnerability_scanning.minimum_severity),
                    0
                )
                current_level = severity_order.get(vuln.severity, 0)
                
                if current_level < min_level:
                    continue
            
            # Apply CVSS thresholds if available
            if vuln.cvss_scores and self._policy_config.cvss_thresholds:
                primary_score = vuln.get_primary_cvss_score()
                if primary_score:
                    severity_key = vuln.severity.value
                    if severity_key in self._policy_config.cvss_thresholds:
                        threshold = self._policy_config.cvss_thresholds[severity_key]
                        if primary_score < threshold.min_score:
                            continue
            
            filtered.append(vuln)
        
        return filtered
    
    async def get_vulnerability_details(
        self, 
        vulnerability_id: str,
        preferred_source: Optional[VulnerabilitySource] = None
    ) -> Optional[VulnerabilityDetails]:
        """Get detailed information for a specific vulnerability."""
        if preferred_source and preferred_source in self._clients:
            client = self._clients[preferred_source]
            result = await client.get_vulnerability_details(vulnerability_id)
            if result:
                return result
        
        # Try all sources if preferred source fails or not specified
        for source, client in self._clients.items():
            if source == preferred_source:
                continue  # Already tried
            
            try:
                result = await client.get_vulnerability_details(vulnerability_id)
                if result:
                    return result
            except Exception as e:
                logger.debug(f"Failed to get {vulnerability_id} from {source.value}: {e}")
        
        return None