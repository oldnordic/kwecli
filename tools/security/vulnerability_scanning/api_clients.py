"""
Vulnerability Scanning API Clients.

This module provides enterprise-grade API clients for vulnerability data sources
including OSV.dev, NVD API 2.0, and GitHub Security Advisory API with comprehensive
rate limiting, caching, authentication, and error handling.
"""

import asyncio
import aiohttp
import hashlib
import json
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Set, Union
from decimal import Decimal
import logging
from urllib.parse import urljoin

from .models import (
    PackageInfo, VulnerabilityDetails, VulnerabilitySeverity,
    VulnerabilitySource, CVSSScore, VulnerabilityReference,
    VulnerabilityAffected
)


logger = logging.getLogger(__name__)


@dataclass
class RateLimitConfig:
    """Rate limiting configuration for API clients."""
    requests_per_minute: int = 60
    requests_per_hour: int = 1000
    burst_allowance: int = 10
    backoff_factor: float = 1.5
    max_backoff_seconds: int = 300


@dataclass
class CacheConfig:
    """Caching configuration for API responses."""
    enabled: bool = True
    ttl_seconds: int = 3600  # 1 hour default
    max_cache_size: int = 1000
    vulnerability_ttl_seconds: int = 7200  # 2 hours for vulnerabilities
    package_ttl_seconds: int = 1800  # 30 minutes for package queries


@dataclass
class APIClientConfig:
    """Configuration for vulnerability scanning API clients."""
    base_url: str
    api_key: Optional[str] = None
    user_agent: str = "KWE-CLI-Security/1.0"
    timeout_seconds: int = 30
    max_retries: int = 3
    rate_limit: RateLimitConfig = field(default_factory=RateLimitConfig)
    cache: CacheConfig = field(default_factory=CacheConfig)


class RateLimiter:
    """Enterprise-grade rate limiter with sliding window and burst handling."""
    
    def __init__(self, config: RateLimitConfig):
        self.config = config
        self.requests_minute: List[float] = []
        self.requests_hour: List[float] = []
        self.burst_tokens = config.burst_allowance
        self.last_reset = time.time()
        self._lock = asyncio.Lock()
    
    async def acquire(self) -> bool:
        """Acquire permission to make a request."""
        async with self._lock:
            now = time.time()
            
            # Clean old requests
            minute_ago = now - 60
            hour_ago = now - 3600
            
            self.requests_minute = [t for t in self.requests_minute if t > minute_ago]
            self.requests_hour = [t for t in self.requests_hour if t > hour_ago]
            
            # Reset burst tokens periodically
            if now - self.last_reset > 60:
                self.burst_tokens = min(
                    self.config.burst_allowance,
                    self.burst_tokens + 1
                )
                self.last_reset = now
            
            # Check hour limit first
            if len(self.requests_hour) >= self.config.requests_per_hour:
                return False
            
            # Check minute limit and burst tokens
            minute_limit_exceeded = len(self.requests_minute) >= self.config.requests_per_minute
            if minute_limit_exceeded:
                if self.burst_tokens <= 0:
                    return False
                else:
                    # Use burst token
                    self.burst_tokens -= 1
            
            # Record request
            self.requests_minute.append(now)
            self.requests_hour.append(now)
            return True
    
    def get_wait_time(self) -> float:
        """Get recommended wait time before next request."""
        now = time.time()
        minute_ago = now - 60
        
        recent_requests = [t for t in self.requests_minute if t > minute_ago]
        if len(recent_requests) >= self.config.requests_per_minute:
            oldest_request = min(recent_requests)
            return max(0, oldest_request + 60 - now)
        
        return 0


class ResponseCache:
    """In-memory response cache with TTL and size limits."""
    
    def __init__(self, config: CacheConfig):
        self.config = config
        self.cache: Dict[str, Dict[str, Any]] = {}
        self._lock = asyncio.Lock()
    
    def _generate_key(self, url: str, params: Dict[str, Any]) -> str:
        """Generate cache key from URL and parameters."""
        key_data = f"{url}:{json.dumps(params, sort_keys=True)}"
        return hashlib.sha256(key_data.encode()).hexdigest()
    
    async def get(self, url: str, params: Dict[str, Any]) -> Optional[Any]:
        """Get cached response if valid."""
        if not self.config.enabled:
            return None
            
        async with self._lock:
            key = self._generate_key(url, params)
            if key in self.cache:
                entry = self.cache[key]
                if entry['expires'] > time.time():
                    logger.debug(f"Cache hit for {url}")
                    return entry['data']
                else:
                    del self.cache[key]
        
        return None
    
    async def set(self, url: str, params: Dict[str, Any], data: Any, ttl: Optional[int] = None) -> None:
        """Cache response data."""
        if not self.config.enabled:
            return
            
        async with self._lock:
            # Enforce size limit
            if len(self.cache) >= self.config.max_cache_size:
                # Remove oldest entries
                oldest_keys = sorted(
                    self.cache.keys(),
                    key=lambda k: self.cache[k]['created']
                )[:100]  # Remove 100 oldest entries
                for old_key in oldest_keys:
                    del self.cache[old_key]
            
            key = self._generate_key(url, params)
            expires = time.time() + (ttl or self.config.ttl_seconds)
            
            self.cache[key] = {
                'data': data,
                'expires': expires,
                'created': time.time()
            }
            logger.debug(f"Cached response for {url}")


class BaseVulnerabilityClient(ABC):
    """Base class for vulnerability data source clients."""
    
    def __init__(self, config: APIClientConfig):
        self.config = config
        self.rate_limiter = RateLimiter(config.rate_limit)
        self.cache = ResponseCache(config.cache)
        self._session: Optional[aiohttp.ClientSession] = None
    
    async def __aenter__(self):
        """Async context manager entry."""
        connector = aiohttp.TCPConnector(limit=10, ttl_dns_cache=300)
        timeout = aiohttp.ClientTimeout(total=self.config.timeout_seconds)
        
        self._session = aiohttp.ClientSession(
            connector=connector,
            timeout=timeout,
            headers={'User-Agent': self.config.user_agent}
        )
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        if self._session:
            await self._session.close()
    
    async def _make_request(
        self,
        method: str,
        url: str,
        params: Optional[Dict[str, Any]] = None,
        headers: Optional[Dict[str, str]] = None,
        ttl: Optional[int] = None
    ) -> Dict[str, Any]:
        """Make rate-limited and cached HTTP request."""
        params = params or {}
        headers = headers or {}
        
        # Check cache first
        cached_response = await self.cache.get(url, params)
        if cached_response is not None:
            return cached_response
        
        # Apply rate limiting
        retries = 0
        while retries < self.config.max_retries:
            if await self.rate_limiter.acquire():
                break
                
            wait_time = self.rate_limiter.get_wait_time()
            if wait_time > 0:
                logger.warning(f"Rate limited, waiting {wait_time:.2f}s")
                await asyncio.sleep(wait_time)
            
            retries += 1
        
        if retries >= self.config.max_retries:
            raise Exception("Rate limit exceeded, max retries reached")
        
        # Make request
        try:
            async with self._session.request(
                method,
                url,
                params=params,
                headers=headers
            ) as response:
                response.raise_for_status()
                data = await response.json()
                
                # Cache successful response
                await self.cache.set(url, params, data, ttl)
                return data
                
        except aiohttp.ClientError as e:
            logger.error(f"Request failed: {e}")
            raise
        except Exception as e:
            logger.error(f"Unexpected error in request: {e}")
            raise
    
    @abstractmethod
    async def query_vulnerabilities(
        self,
        package: PackageInfo
    ) -> List[VulnerabilityDetails]:
        """Query vulnerabilities for a package."""
        pass
    
    @abstractmethod
    async def get_vulnerability_details(
        self,
        vulnerability_id: str
    ) -> Optional[VulnerabilityDetails]:
        """Get detailed information for a specific vulnerability."""
        pass


class OSVClient(BaseVulnerabilityClient):
    """OSV.dev API client with enterprise features."""
    
    def __init__(self, config: Optional[APIClientConfig] = None):
        if config is None:
            config = APIClientConfig(
                base_url="https://api.osv.dev",
                rate_limit=RateLimitConfig(
                    requests_per_minute=120,  # OSV allows higher rates
                    requests_per_hour=2000
                )
            )
        super().__init__(config)
    
    async def query_vulnerabilities(
        self,
        package: PackageInfo
    ) -> List[VulnerabilityDetails]:
        """Query OSV for vulnerabilities affecting a package."""
        url = urljoin(self.config.base_url, "/v1/query")
        
        # Build OSV query
        query_data = {
            "package": {
                "name": package.name,
                "ecosystem": package.ecosystem.value.upper()
            }
        }
        
        if package.version:
            query_data["version"] = package.version
        
        try:
            # OSV uses POST for queries
            async with self._session.post(url, json=query_data) as response:
                response.raise_for_status()
                data = await response.json()
            
            vulnerabilities = []
            for vuln_data in data.get("vulns", []):
                vulnerability = self._parse_osv_vulnerability(vuln_data)
                if vulnerability:
                    vulnerabilities.append(vulnerability)
            
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"OSV query failed for {package.name}: {e}")
            return []
    
    async def get_vulnerability_details(
        self,
        vulnerability_id: str
    ) -> Optional[VulnerabilityDetails]:
        """Get detailed vulnerability information from OSV."""
        url = urljoin(self.config.base_url, f"/v1/vulns/{vulnerability_id}")
        
        try:
            data = await self._make_request(
                "GET",
                url,
                ttl=self.config.cache.vulnerability_ttl_seconds
            )
            return self._parse_osv_vulnerability(data)
            
        except Exception as e:
            logger.error(f"Failed to get OSV vulnerability {vulnerability_id}: {e}")
            return None
    
    def _parse_osv_vulnerability(self, data: Dict[str, Any]) -> Optional[VulnerabilityDetails]:
        """Parse OSV vulnerability data into our model."""
        try:
            # Parse CVSS scores
            cvss_scores = []
            if "severity" in data:
                for severity_data in data["severity"]:
                    if severity_data.get("type") == "CVSS_V3":
                        score_data = severity_data.get("score", "")
                        if "/" in score_data:
                            vector_string = score_data
                            # Extract base score from vector string
                            base_score = self._extract_cvss_score(vector_string)
                            if base_score:
                                cvss_scores.append(CVSSScore(
                                    version="3.1",
                                    vector_string=vector_string,
                                    base_score=base_score
                                ))
            
            # Parse references
            references = []
            for ref_data in data.get("references", []):
                references.append(VulnerabilityReference(
                    url=ref_data.get("url", ""),
                    type=ref_data.get("type", "WEB"),
                    description=ref_data.get("description")
                ))
            
            # Determine severity from CVSS or use moderate as default
            severity = VulnerabilitySeverity.MEDIUM
            if cvss_scores:
                base_score = cvss_scores[0].base_score
                severity = self._cvss_to_severity(base_score)
            
            return VulnerabilityDetails(
                id=data.get("id", ""),
                summary=data.get("summary", ""),
                details=data.get("details", ""),
                severity=severity,
                source=VulnerabilitySource.OSV,
                cvss_scores=cvss_scores,
                references=references,
                aliases=data.get("aliases", []),
                published=self._parse_timestamp(data.get("published")),
                modified=self._parse_timestamp(data.get("modified"))
            )
            
        except Exception as e:
            logger.error(f"Failed to parse OSV vulnerability: {e}")
            return None
    
    def _extract_cvss_score(self, vector_string: str) -> Optional[Decimal]:
        """Extract CVSS base score from vector string."""
        try:
            # This is a simplified extraction - in production you'd use a proper CVSS library
            if "CVSS:" in vector_string and "/" in vector_string:
                # For now, return a placeholder - proper implementation would calculate
                return Decimal("7.5")  # Moderate default
        except Exception:
            pass
        return None
    
    def _cvss_to_severity(self, score: Decimal) -> VulnerabilitySeverity:
        """Convert CVSS score to severity level."""
        if score >= 9.0:
            return VulnerabilitySeverity.CRITICAL
        elif score >= 7.0:
            return VulnerabilitySeverity.HIGH
        elif score >= 4.0:
            return VulnerabilitySeverity.MEDIUM
        elif score >= 0.1:
            return VulnerabilitySeverity.LOW
        else:
            return VulnerabilitySeverity.INFO
    
    def _parse_timestamp(self, timestamp_str: Optional[str]) -> Optional[datetime]:
        """Parse ISO timestamp string."""
        if not timestamp_str:
            return None
        try:
            return datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        except Exception:
            return None


class NVDClient(BaseVulnerabilityClient):
    """NVD API 2.0 client with authentication and enterprise features."""
    
    def __init__(self, api_key: Optional[str] = None, config: Optional[APIClientConfig] = None):
        if config is None:
            rate_config = RateLimitConfig(
                requests_per_minute=50 if api_key else 5,  # Higher limits with API key
                requests_per_hour=1000 if api_key else 100
            )
            config = APIClientConfig(
                base_url="https://services.nvd.nist.gov/rest/json",
                api_key=api_key,
                rate_limit=rate_config
            )
        super().__init__(config)
    
    async def query_vulnerabilities(
        self,
        package: PackageInfo
    ) -> List[VulnerabilityDetails]:
        """Query NVD for vulnerabilities affecting a package."""
        # NVD doesn't have direct package queries like OSV
        # We'd need to search by keywords or CPE
        url = urljoin(self.config.base_url, "/cves/2.0")
        
        headers = {}
        if self.config.api_key:
            headers["apiKey"] = self.config.api_key
        
        params = {
            "keywordSearch": package.name,
            "resultsPerPage": 100
        }
        
        try:
            data = await self._make_request(
                "GET",
                url,
                params=params,
                headers=headers,
                ttl=self.config.cache.vulnerability_ttl_seconds
            )
            
            vulnerabilities = []
            for cve_data in data.get("vulnerabilities", []):
                vulnerability = self._parse_nvd_vulnerability(cve_data)
                if vulnerability:
                    vulnerabilities.append(vulnerability)
            
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"NVD query failed for {package.name}: {e}")
            return []
    
    async def get_vulnerability_details(
        self,
        vulnerability_id: str
    ) -> Optional[VulnerabilityDetails]:
        """Get detailed vulnerability information from NVD."""
        url = urljoin(self.config.base_url, "/cves/2.0")
        
        headers = {}
        if self.config.api_key:
            headers["apiKey"] = self.config.api_key
        
        params = {"cveId": vulnerability_id}
        
        try:
            data = await self._make_request(
                "GET",
                url,
                params=params,
                headers=headers,
                ttl=self.config.cache.vulnerability_ttl_seconds
            )
            
            vulnerabilities = data.get("vulnerabilities", [])
            if vulnerabilities:
                return self._parse_nvd_vulnerability(vulnerabilities[0])
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to get NVD vulnerability {vulnerability_id}: {e}")
            return None
    
    def _parse_nvd_vulnerability(self, data: Dict[str, Any]) -> Optional[VulnerabilityDetails]:
        """Parse NVD vulnerability data into our model."""
        try:
            cve_data = data.get("cve", {})
            
            # Parse CVSS scores
            cvss_scores = []
            metrics = cve_data.get("metrics", {})
            
            # CVSS 3.1
            if "cvssMetricV31" in metrics:
                for metric in metrics["cvssMetricV31"]:
                    cvss_data = metric.get("cvssData", {})
                    cvss_scores.append(CVSSScore(
                        version="3.1",
                        vector_string=cvss_data.get("vectorString", ""),
                        base_score=Decimal(str(cvss_data.get("baseScore", 0)))
                    ))
            
            # Parse references
            references = []
            for ref_data in cve_data.get("references", []):
                references.append(VulnerabilityReference(
                    url=ref_data.get("url", ""),
                    type="WEB"  # NVD doesn't specify reference types
                ))
            
            # Get description
            descriptions = cve_data.get("descriptions", [])
            description = ""
            for desc in descriptions:
                if desc.get("lang") == "en":
                    description = desc.get("value", "")
                    break
            
            # Determine severity
            severity = VulnerabilitySeverity.MEDIUM
            if cvss_scores:
                severity = self._cvss_to_severity(cvss_scores[0].base_score)
            
            return VulnerabilityDetails(
                id=cve_data.get("id", ""),
                summary=description[:200] + "..." if len(description) > 200 else description,
                details=description,
                severity=severity,
                source=VulnerabilitySource.NVD,
                cvss_scores=cvss_scores,
                references=references,
                published=self._parse_nvd_timestamp(cve_data.get("published")),
                modified=self._parse_nvd_timestamp(cve_data.get("lastModified"))
            )
            
        except Exception as e:
            logger.error(f"Failed to parse NVD vulnerability: {e}")
            return None
    
    def _cvss_to_severity(self, score: Decimal) -> VulnerabilitySeverity:
        """Convert CVSS score to severity level."""
        if score >= 9.0:
            return VulnerabilitySeverity.CRITICAL
        elif score >= 7.0:
            return VulnerabilitySeverity.HIGH
        elif score >= 4.0:
            return VulnerabilitySeverity.MEDIUM
        elif score >= 0.1:
            return VulnerabilitySeverity.LOW
        else:
            return VulnerabilitySeverity.INFO
    
    def _parse_nvd_timestamp(self, timestamp_str: Optional[str]) -> Optional[datetime]:
        """Parse NVD timestamp string."""
        if not timestamp_str:
            return None
        try:
            return datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        except Exception:
            return None


class GitHubAdvisoryClient(BaseVulnerabilityClient):
    """GitHub Security Advisory API client."""
    
    def __init__(self, api_key: Optional[str] = None, config: Optional[APIClientConfig] = None):
        if config is None:
            config = APIClientConfig(
                base_url="https://api.github.com",
                api_key=api_key,
                rate_limit=RateLimitConfig(
                    requests_per_minute=60 if not api_key else 5000,
                    requests_per_hour=1000 if not api_key else 5000
                )
            )
        super().__init__(config)
    
    async def query_vulnerabilities(
        self,
        package: PackageInfo
    ) -> List[VulnerabilityDetails]:
        """Query GitHub Security Advisory for package vulnerabilities."""
        url = urljoin(self.config.base_url, "/advisories")
        
        headers = {}
        if self.config.api_key:
            headers["Authorization"] = f"token {self.config.api_key}"
        
        # Map ecosystem names
        ecosystem_map = {
            "npm": "npm",
            "pypi": "pip",
            "cargo": "rust",
            "maven": "maven",
            "nuget": "nuget",
            "go": "go",
            "rubygems": "rubygems",
            "composer": "composer"
        }
        
        ecosystem = ecosystem_map.get(package.ecosystem.value, package.ecosystem.value)
        
        params = {
            "ecosystem": ecosystem,
            "affects": package.name,
            "per_page": 100
        }
        
        try:
            data = await self._make_request(
                "GET",
                url,
                params=params,
                headers=headers,
                ttl=self.config.cache.vulnerability_ttl_seconds
            )
            
            vulnerabilities = []
            for advisory in data:
                vulnerability = self._parse_github_advisory(advisory)
                if vulnerability:
                    vulnerabilities.append(vulnerability)
            
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"GitHub Advisory query failed for {package.name}: {e}")
            return []
    
    async def get_vulnerability_details(
        self,
        vulnerability_id: str
    ) -> Optional[VulnerabilityDetails]:
        """Get detailed vulnerability information from GitHub Advisory."""
        url = urljoin(self.config.base_url, f"/advisories/{vulnerability_id}")
        
        headers = {}
        if self.config.api_key:
            headers["Authorization"] = f"token {self.config.api_key}"
        
        try:
            data = await self._make_request(
                "GET",
                url,
                headers=headers,
                ttl=self.config.cache.vulnerability_ttl_seconds
            )
            return self._parse_github_advisory(data)
            
        except Exception as e:
            logger.error(f"Failed to get GitHub advisory {vulnerability_id}: {e}")
            return None
    
    def _parse_github_advisory(self, data: Dict[str, Any]) -> Optional[VulnerabilityDetails]:
        """Parse GitHub Security Advisory data into our model."""
        try:
            # Parse CVSS scores
            cvss_scores = []
            if "cvss" in data and data["cvss"]:
                cvss_data = data["cvss"]
                cvss_scores.append(CVSSScore(
                    version="3.1",  # GitHub uses CVSS 3.1
                    vector_string=cvss_data.get("vector_string", ""),
                    base_score=Decimal(str(cvss_data.get("score", 0)))
                ))
            
            # Parse references
            references = []
            for ref_url in data.get("references", []):
                references.append(VulnerabilityReference(
                    url=ref_url,
                    type="WEB"
                ))
            
            # Map GitHub severity to our severity
            severity_map = {
                "critical": VulnerabilitySeverity.CRITICAL,
                "high": VulnerabilitySeverity.HIGH,
                "moderate": VulnerabilitySeverity.MEDIUM,
                "low": VulnerabilitySeverity.LOW
            }
            
            severity = severity_map.get(
                data.get("severity", "moderate").lower(),
                VulnerabilitySeverity.MEDIUM
            )
            
            return VulnerabilityDetails(
                id=data.get("ghsa_id", data.get("cve_id", "")),
                summary=data.get("summary", ""),
                details=data.get("description", ""),
                severity=severity,
                source=VulnerabilitySource.GITHUB_ADVISORY,
                cvss_scores=cvss_scores,
                references=references,
                aliases=[data.get("cve_id")] if data.get("cve_id") else [],
                published=self._parse_github_timestamp(data.get("published_at")),
                modified=self._parse_github_timestamp(data.get("updated_at"))
            )
            
        except Exception as e:
            logger.error(f"Failed to parse GitHub advisory: {e}")
            return None
    
    def _parse_github_timestamp(self, timestamp_str: Optional[str]) -> Optional[datetime]:
        """Parse GitHub timestamp string."""
        if not timestamp_str:
            return None
        try:
            return datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
        except Exception:
            return None