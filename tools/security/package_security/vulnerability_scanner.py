"""
Enterprise Vulnerability Scanner with OSV.dev API Integration.

This module provides comprehensive vulnerability scanning capabilities with:
- Real-time OSV.dev API integration for vulnerability data
- CVSS v3.1 scoring and severity classification
- Concurrent scanning with rate limiting
- Result caching for performance optimization
- Support for multiple package ecosystems
"""

import asyncio
import hashlib
import json
import logging
import time
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Set
from urllib.parse import urljoin
import re

import httpx


@dataclass
class CVSSScore:
    """CVSS v3.1 vulnerability score representation."""
    
    version: str = "3.1"
    base_score: float = 0.0
    vector: str = ""
    attack_vector: str = "UNKNOWN"
    attack_complexity: str = "UNKNOWN"
    privileges_required: str = "UNKNOWN"
    user_interaction: str = "UNKNOWN"
    scope: str = "UNKNOWN"
    confidentiality_impact: str = "UNKNOWN"
    integrity_impact: str = "UNKNOWN"
    availability_impact: str = "UNKNOWN"
    
    @classmethod
    def from_vector(cls, vector: str) -> 'CVSSScore':
        """Parse CVSS vector string and calculate base score."""
        try:
            if not vector or not vector.startswith("CVSS:3."):
                return cls()
            
            # Parse CVSS vector components
            parts = vector.split('/')
            metrics = {}
            
            for part in parts[1:]:  # Skip CVSS:3.x part
                if ':' in part:
                    key, value = part.split(':', 1)
                    metrics[key] = value
            
            # Extract metrics
            attack_vector = cls._map_attack_vector(metrics.get('AV', 'U'))
            attack_complexity = cls._map_attack_complexity(metrics.get('AC', 'H'))
            privileges_required = cls._map_privileges_required(metrics.get('PR', 'H'))
            user_interaction = cls._map_user_interaction(metrics.get('UI', 'R'))
            scope = cls._map_scope(metrics.get('S', 'U'))
            confidentiality = cls._map_impact(metrics.get('C', 'N'))
            integrity = cls._map_impact(metrics.get('I', 'N'))
            availability = cls._map_impact(metrics.get('A', 'N'))
            
            # Calculate base score using CVSS 3.1 formula
            base_score = cls._calculate_base_score(
                metrics.get('AV', 'U'),
                metrics.get('AC', 'H'),
                metrics.get('PR', 'H'),
                metrics.get('UI', 'R'),
                metrics.get('S', 'U'),
                metrics.get('C', 'N'),
                metrics.get('I', 'N'),
                metrics.get('A', 'N')
            )
            
            return cls(
                vector=vector,
                base_score=base_score,
                attack_vector=attack_vector,
                attack_complexity=attack_complexity,
                privileges_required=privileges_required,
                user_interaction=user_interaction,
                scope=scope,
                confidentiality_impact=confidentiality,
                integrity_impact=integrity,
                availability_impact=availability
            )
            
        except Exception as e:
            logging.error(f"Failed to parse CVSS vector {vector}: {e}")
            return cls()
    
    @staticmethod
    def _map_attack_vector(av: str) -> str:
        """Map attack vector abbreviation to full name."""
        mapping = {"N": "NETWORK", "A": "ADJACENT", "L": "LOCAL", "P": "PHYSICAL"}
        return mapping.get(av, "UNKNOWN")
    
    @staticmethod
    def _map_attack_complexity(ac: str) -> str:
        """Map attack complexity abbreviation to full name."""
        mapping = {"L": "LOW", "H": "HIGH"}
        return mapping.get(ac, "UNKNOWN")
    
    @staticmethod
    def _map_privileges_required(pr: str) -> str:
        """Map privileges required abbreviation to full name."""
        mapping = {"N": "NONE", "L": "LOW", "H": "HIGH"}
        return mapping.get(pr, "UNKNOWN")
    
    @staticmethod
    def _map_user_interaction(ui: str) -> str:
        """Map user interaction abbreviation to full name."""
        mapping = {"N": "NONE", "R": "REQUIRED"}
        return mapping.get(ui, "UNKNOWN")
    
    @staticmethod
    def _map_scope(s: str) -> str:
        """Map scope abbreviation to full name."""
        mapping = {"U": "UNCHANGED", "C": "CHANGED"}
        return mapping.get(s, "UNKNOWN")
    
    @staticmethod
    def _map_impact(impact: str) -> str:
        """Map impact abbreviation to full name."""
        mapping = {"N": "NONE", "L": "LOW", "H": "HIGH"}
        return mapping.get(impact, "UNKNOWN")
    
    @staticmethod
    def _calculate_base_score(av: str, ac: str, pr: str, ui: str, s: str, c: str, i: str, a: str) -> float:
        """Calculate CVSS 3.1 base score using official formula."""
        try:
            # Base metric scores (official CVSS 3.1 values)
            av_score = {"N": 0.85, "A": 0.62, "L": 0.55, "P": 0.2}.get(av, 0.0)
            ac_score = {"L": 0.77, "H": 0.44}.get(ac, 0.44)
            pr_score = {"N": 0.85, "L": 0.62 if s == "U" else 0.68, "H": 0.27 if s == "U" else 0.50}.get(pr, 0.0)
            ui_score = {"N": 0.85, "R": 0.62}.get(ui, 0.62)
            c_score = {"N": 0.0, "L": 0.22, "H": 0.56}.get(c, 0.0)
            i_score = {"N": 0.0, "L": 0.22, "H": 0.56}.get(i, 0.0)
            a_score = {"N": 0.0, "L": 0.22, "H": 0.56}.get(a, 0.0)
            
            # Impact sub-score calculation
            iss = 1 - ((1 - c_score) * (1 - i_score) * (1 - a_score))
            
            if s == "U":  # Unchanged scope
                impact = 6.42 * iss
            else:  # Changed scope
                impact = 7.52 * (iss - 0.029) - 3.25 * ((iss - 0.02) ** 15)
            
            # Exploitability sub-score
            exploitability = 8.22 * av_score * ac_score * pr_score * ui_score
            
            # Base score calculation
            if impact <= 0:
                return 0.0
            
            if s == "U":
                base_score = min(10.0, impact + exploitability)
            else:
                base_score = min(10.0, 1.08 * (impact + exploitability))
            
            # Round up to nearest 0.1 (as per CVSS spec)
            import math
            return math.ceil(base_score * 10.0) / 10.0
            
        except Exception:
            return 0.0
    
    def get_severity_level(self) -> str:
        """Get severity level based on base score."""
        if self.base_score >= 9.0:
            return "CRITICAL"
        elif self.base_score >= 7.0:
            return "HIGH"
        elif self.base_score >= 4.0:
            return "MEDIUM"
        elif self.base_score > 0.0:
            return "LOW"
        else:
            return "NONE"


@dataclass
class VulnerabilityReport:
    """Comprehensive vulnerability report."""
    
    vulnerability_id: str
    package_name: str
    ecosystem: str
    affected_versions: List[str]
    summary: str
    details: str
    cvss_score: CVSSScore
    severity: str
    published_date: datetime
    modified_date: datetime
    references: List[str] = field(default_factory=list)
    cwe_ids: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization."""
        return {
            "vulnerability_id": self.vulnerability_id,
            "package_name": self.package_name,
            "ecosystem": self.ecosystem,
            "affected_versions": self.affected_versions,
            "summary": self.summary,
            "details": self.details,
            "cvss_score": {
                "version": self.cvss_score.version,
                "base_score": self.cvss_score.base_score,
                "vector": self.cvss_score.vector,
                "severity": self.cvss_score.get_severity_level()
            },
            "severity": self.severity,
            "published_date": self.published_date.isoformat() if self.published_date else None,
            "modified_date": self.modified_date.isoformat() if self.modified_date else None,
            "references": self.references,
            "cwe_ids": self.cwe_ids
        }
    
    def to_json(self) -> str:
        """Convert to JSON string."""
        return json.dumps(self.to_dict(), indent=2)


class OSVClient:
    """OSV.dev API client with rate limiting and error handling."""
    
    def __init__(
        self,
        api_url: str = "https://api.osv.dev",
        timeout: int = 30,
        max_retries: int = 3
    ):
        self.api_url = api_url
        self.timeout = timeout
        self.max_retries = max_retries
        self.logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")
    
    async def query_package(
        self,
        package_name: str,
        ecosystem: str,
        version: Optional[str] = None
    ) -> List[VulnerabilityReport]:
        """Query OSV.dev API for package vulnerabilities."""
        try:
            query_data = {
                "package": {
                    "name": package_name,
                    "ecosystem": ecosystem
                }
            }
            
            if version:
                query_data["version"] = version
            
            url = urljoin(self.api_url, "/v1/query")
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                for attempt in range(self.max_retries):
                    try:
                        response = await client.post(url, json=query_data)
                        
                        if response.status_code == 429:
                            # Rate limited - wait and retry
                            retry_after = int(response.headers.get("retry-after", 1))
                            self.logger.warning(f"Rate limited, waiting {retry_after} seconds")
                            await asyncio.sleep(retry_after)
                            continue
                        
                        response.raise_for_status()
                        data = response.json()
                        
                        return self._parse_osv_response(data, package_name, ecosystem)
                        
                    except httpx.HTTPStatusError as e:
                        self.logger.error(f"HTTP error querying OSV for {package_name}: {e}")
                        if attempt == self.max_retries - 1:
                            break
                        await asyncio.sleep(2 ** attempt)  # Exponential backoff
                    
                    except Exception as e:
                        self.logger.error(f"Error querying OSV for {package_name}: {e}")
                        if attempt == self.max_retries - 1:
                            break
                        await asyncio.sleep(2 ** attempt)
            
            return []
            
        except Exception as e:
            self.logger.error(f"Failed to query OSV.dev for {package_name}: {e}")
            return []
    
    def _parse_osv_response(
        self,
        data: Dict[str, Any],
        package_name: str,
        ecosystem: str
    ) -> List[VulnerabilityReport]:
        """Parse OSV.dev API response into vulnerability reports."""
        vulnerabilities = []
        
        try:
            vulns = data.get("vulns", [])
            
            for vuln_data in vulns:
                vuln = self._parse_vulnerability(vuln_data, package_name, ecosystem)
                if vuln:
                    vulnerabilities.append(vuln)
            
        except Exception as e:
            self.logger.error(f"Failed to parse OSV response: {e}")
        
        return vulnerabilities
    
    def _parse_vulnerability(
        self,
        vuln_data: Dict[str, Any],
        package_name: str,
        ecosystem: str
    ) -> Optional[VulnerabilityReport]:
        """Parse individual vulnerability from OSV data."""
        try:
            vuln_id = vuln_data.get("id", "")
            summary = vuln_data.get("summary", "")
            details = vuln_data.get("details", "")
            
            # Parse CVSS score
            cvss_score = CVSSScore()
            severity_data = vuln_data.get("severity", [])
            for sev in severity_data:
                if sev.get("type") == "CVSS_V3":
                    cvss_vector = sev.get("score", "")
                    cvss_score = CVSSScore.from_vector(cvss_vector)
                    break
            
            # Parse affected versions
            affected_versions = []
            affected = vuln_data.get("affected", [])
            for affect in affected:
                ranges = affect.get("ranges", [])
                for range_data in ranges:
                    events = range_data.get("events", [])
                    for event in events:
                        if "introduced" in event:
                            affected_versions.append(event["introduced"])
            
            # Parse dates
            published_date = self._parse_date(vuln_data.get("published"))
            modified_date = self._parse_date(vuln_data.get("modified"))
            
            # Parse references
            references = []
            refs = vuln_data.get("references", [])
            for ref in refs:
                url = ref.get("url")
                if url:
                    references.append(url)
            
            # Parse CWE IDs
            cwe_ids = []
            database_specific = vuln_data.get("database_specific", {})
            cwe_list = database_specific.get("cwe_ids", [])
            for cwe in cwe_list:
                if isinstance(cwe, str):
                    cwe_ids.append(cwe)
            
            return VulnerabilityReport(
                vulnerability_id=vuln_id,
                package_name=package_name,
                ecosystem=ecosystem,
                affected_versions=affected_versions,
                summary=summary,
                details=details,
                cvss_score=cvss_score,
                severity=cvss_score.get_severity_level(),
                published_date=published_date,
                modified_date=modified_date,
                references=references,
                cwe_ids=cwe_ids
            )
            
        except Exception as e:
            self.logger.error(f"Failed to parse vulnerability data: {e}")
            return None
    
    def _parse_date(self, date_str: Optional[str]) -> Optional[datetime]:
        """Parse ISO date string to datetime object."""
        if not date_str:
            return None
        
        try:
            # Handle various ISO date formats
            if date_str.endswith('Z'):
                date_str = date_str[:-1] + '+00:00'
            
            return datetime.fromisoformat(date_str.replace('Z', '+00:00'))
        except Exception:
            return None


class VulnerabilityScanner:
    """Enterprise vulnerability scanner with OSV.dev integration."""
    
    SUPPORTED_ECOSYSTEMS = {
        "npm", "pypi", "crates.io", "go", "maven", "nuget",
        "packagist", "rubygems", "hex", "pub", "conan"
    }
    
    SEVERITY_HIERARCHY = {
        "CRITICAL": 4,
        "HIGH": 3,
        "MEDIUM": 2,
        "LOW": 1,
        "NONE": 0
    }
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize vulnerability scanner with configuration."""
        self.config = config or {}
        self.logger = logging.getLogger(f"{self.__class__.__module__}.{self.__class__.__name__}")
        
        # Initialize OSV client
        self.osv_client = OSVClient(
            api_url=self.config.get("osv_api_url", "https://api.osv.dev"),
            timeout=self.config.get("timeout", 30),
            max_retries=self.config.get("max_retries", 3)
        )
        
        # Configure caching
        self.cache_ttl = self.config.get("cache_ttl", 3600)  # 1 hour default
        self.cache: Dict[str, Dict[str, Any]] = {}
        
        # Configure concurrency
        max_concurrent = self.config.get("max_concurrent_requests", 5)
        self.semaphore = asyncio.Semaphore(max_concurrent)
        
        # Configure severity threshold
        self.severity_threshold = self.config.get("severity_threshold", "LOW")
    
    async def scan_package(
        self,
        package_name: str,
        ecosystem: str,
        version: Optional[str] = None
    ) -> Dict[str, Any]:
        """Scan a single package for vulnerabilities."""
        try:
            # Input validation
            if not package_name or not package_name.strip():
                return {
                    "success": False,
                    "error": "Package name cannot be empty",
                    "package_name": package_name,
                    "ecosystem": ecosystem
                }
            
            if not self._is_ecosystem_supported(ecosystem):
                return {
                    "success": False,
                    "error": f"Unsupported ecosystem: {ecosystem}",
                    "package_name": package_name,
                    "ecosystem": ecosystem
                }
            
            # Check cache first
            cache_key = self._get_cache_key(package_name, ecosystem, version)
            cached_result = self._get_cached_result(cache_key)
            if cached_result:
                cached_result["from_cache"] = True
                return cached_result
            
            # Query OSV.dev for vulnerabilities
            vulnerabilities = await self.osv_client.query_package(package_name, ecosystem, version)
            
            # Filter by severity threshold
            filtered_vulns = self._filter_by_severity(vulnerabilities)
            
            # Prepare result
            result = {
                "success": True,
                "package_name": package_name,
                "ecosystem": ecosystem,
                "version": version,
                "vulnerabilities": [vuln.to_dict() for vuln in filtered_vulns],
                "vulnerability_count": len(filtered_vulns),
                "highest_severity": self._get_highest_severity(filtered_vulns),
                "scan_timestamp": datetime.now().isoformat(),
                "from_cache": False
            }
            
            # Cache result
            self._cache_result(cache_key, result)
            
            return result
            
        except Exception as e:
            self.logger.error(f"Failed to scan package {package_name}: {e}")
            return {
                "success": False,
                "error": str(e),
                "package_name": package_name,
                "ecosystem": ecosystem,
                "version": version
            }
    
    async def scan_packages(self, packages: List[Dict[str, str]]) -> List[Dict[str, Any]]:
        """Scan multiple packages concurrently."""
        tasks = []
        
        for package_info in packages:
            task = self._scan_with_semaphore(
                package_info.get("name", ""),
                package_info.get("ecosystem", ""),
                package_info.get("version")
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Handle exceptions
        processed_results = []
        for result in results:
            if isinstance(result, Exception):
                processed_results.append({
                    "success": False,
                    "error": str(result),
                    "package_name": "unknown",
                    "ecosystem": "unknown"
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _scan_with_semaphore(
        self,
        package_name: str,
        ecosystem: str,
        version: Optional[str] = None
    ) -> Dict[str, Any]:
        """Scan package with semaphore-controlled concurrency."""
        async with self.semaphore:
            return await self.scan_package(package_name, ecosystem, version)
    
    def _is_ecosystem_supported(self, ecosystem: str) -> bool:
        """Check if ecosystem is supported by the scanner."""
        return ecosystem in self.SUPPORTED_ECOSYSTEMS
    
    def _filter_by_severity(self, vulnerabilities: List[VulnerabilityReport]) -> List[VulnerabilityReport]:
        """Filter vulnerabilities by severity threshold."""
        threshold_level = self.SEVERITY_HIERARCHY.get(self.severity_threshold, 1)
        
        filtered = []
        for vuln in vulnerabilities:
            vuln_level = self.SEVERITY_HIERARCHY.get(vuln.severity, 0)
            if vuln_level >= threshold_level:
                filtered.append(vuln)
        
        return filtered
    
    def _get_highest_severity(self, vulnerabilities: List[VulnerabilityReport]) -> str:
        """Get the highest severity level from vulnerability list."""
        if not vulnerabilities:
            return "NONE"
        
        highest_level = 0
        highest_severity = "NONE"
        
        for vuln in vulnerabilities:
            level = self.SEVERITY_HIERARCHY.get(vuln.severity, 0)
            if level > highest_level:
                highest_level = level
                highest_severity = vuln.severity
        
        return highest_severity
    
    def _get_cache_key(self, package_name: str, ecosystem: str, version: Optional[str] = None) -> str:
        """Generate cache key for package scan."""
        key_data = f"{package_name}:{ecosystem}:{version or 'latest'}"
        return hashlib.md5(key_data.encode()).hexdigest()
    
    def _cache_result(self, cache_key: str, result: Dict[str, Any]) -> None:
        """Cache scan result with TTL."""
        self.cache[cache_key] = {
            "result": result,
            "cached_at": time.time()
        }
    
    def _get_cached_result(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """Get cached scan result if not expired."""
        cached_data = self.cache.get(cache_key)
        if not cached_data:
            return None
        
        # Check if cache is expired
        if time.time() - cached_data["cached_at"] > self.cache_ttl:
            del self.cache[cache_key]
            return None
        
        return cached_data["result"].copy()